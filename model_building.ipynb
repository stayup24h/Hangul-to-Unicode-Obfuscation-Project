{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/stayup24h/Hangul-to-Unicode-Obfuscation-Project/blob/main/model_building.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHqopzICGLpl"
   },
   "outputs": [],
   "source": [
    "# initial\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Reshape, LSTM, Dense, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f90a1c79"
   },
   "outputs": [],
   "source": [
    "#모델 설계\n",
    "\n",
    "def model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    # CNN 레이어\n",
    "    # Conv1_1\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D((2, 2))) # (None, 128, 128, 64)\n",
    "\n",
    "    # Conv2_1\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2))) # (None, 64, 64, 128)\n",
    "\n",
    "    # Conv3_1, Conv3_2\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 1))) # (None, 32, 64, 256)\n",
    "\n",
    "    # Conv4_1\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "    # Conv5_1\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 1))) # (None, 16, 64, 512)\n",
    "\n",
    "    # Conv6_1\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 1))) # (None, 8, 64, 512)\n",
    "\n",
    "    # RNN 레이어를 위한 Reshape\n",
    "    new_width_for_rnn = 64 # CNN 출력의 width\n",
    "    features_per_timestep = 1 * 512 # CNN 출력의 height * channels\n",
    "    model.add(Reshape(target_shape=(new_width_for_rnn, features_per_timestep))) # (None, 64, 512)\n",
    "\n",
    "    # RNN 레이어 (양방향 LSTM)\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "\n",
    "    # 출력 레이어\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fa0fa569"
   },
   "outputs": [],
   "source": [
    "# 모델 체크포인트 관리 클래스\n",
    "class CheckpointManager:\n",
    "    def __init__(self, max_recent=3, extra_interval=50):\n",
    "        self.max_recent = max_recent\n",
    "        self.extra_interval = extra_interval\n",
    "        self.recent_epochs = []\n",
    "\n",
    "    def load(self, model, epoch, checkpoint_path):\n",
    "        path = checkpoint_path.format(epoch=epoch)\n",
    "        if os.path.exists(path):\n",
    "            model.load_weights(path)\n",
    "            print(f\"Loaded weights from {path}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"No checkpoint found at {path}\")\n",
    "            return False\n",
    "\n",
    "    def save(self, model, epoch):\n",
    "        # Always save at extra_interval epochs\n",
    "        if epoch % self.extra_interval == 0 and epoch not in self.recent_epochs:\n",
    "            path = self.checkpoint_path_template.format(epoch=epoch)\n",
    "            model.save_weights(path)\n",
    "            print(f\"Extra checkpoint saved for epoch {epoch} at {path}\")\n",
    "\n",
    "        # Save recent checkpoints\n",
    "        self.recent_epochs.append(epoch)\n",
    "        if len(self.recent_epochs) > self.max_recent:\n",
    "            # Remove oldest checkpoint from recent\n",
    "            old_epoch = self.recent_epochs.pop(0)\n",
    "            old_path = self.checkpoint_path_template.format(epoch=old_epoch)\n",
    "            if os.path.exists(old_path):\n",
    "                os.remove(old_path)\n",
    "                print(f\"Removed old checkpoint at {old_path}\")\n",
    "\n",
    "        path = self.checkpoint_path_template.format(epoch=epoch)\n",
    "        model.save_weights(path)\n",
    "        print(f\"Checkpoint saved for epoch {epoch} at {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 전처리 함수\n",
    "\n",
    "# 데이터셋 경로 설정 (실제 경로에 맞게 수정 필요)\n",
    "image_dir = \"./data/images\"\n",
    "json_dir = \"./data/labels\"\n",
    "\n",
    "# 모델 입력 형태 및 클래스 수 정의 (실제 데이터에 맞게 조정 필요)\n",
    "# CRNN 모델의 입력 형태: (높이, 너비, 채널)\n",
    "input_shape = (21, 256, 1)  \n",
    "num_classes = 87 # 라벨로 사용되는 class 수\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size=(64, 64)):\n",
    "    img = load_img(image_path, color_mode='grayscale', target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array / 255.0  # 정규화\n",
    "    return img_array\n",
    "\n",
    "def load_and_preprocess_json_label(json_path):\n",
    "    with open(json_path, 'r', encoding='utf-8') as f:\n",
    "        label_data = json.load(f)\n",
    "    # JSON 파일에서 실제 레이블을 추출하는 로직 추가 필요\n",
    "    # 예시: 'label' 키에 해당하는 값을 반환\n",
    "    # 이 부분은 실제 JSON 파일 구조에 따라 달라집니다.\n",
    "    if 'label' in label_data:\n",
    "        return label_data['label']\n",
    "    else:\n",
    "        raise ValueError(f\"JSON 파일에 'label' 키가 없습니다: {json_path}\")\n",
    "\n",
    "# 데이터 제너레이터 (훈련 데이터 로드를 위한)\n",
    "def data_generator(image_filenames, batch_size, input_shape, num_classes):\n",
    "    num_samples = len(image_filenames)\n",
    "    while True:\n",
    "        # 배치 단위로 데이터 셔플 및 로드\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        for i in range(0, num_samples, batch_size):\n",
    "            batch_indices = indices[i:i + batch_size]\n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "\n",
    "            for j in batch_indices:\n",
    "                image_filename = image_filenames[j]\n",
    "                image_path = os.path.join(image_dir, image_filename)\n",
    "                json_filename = image_filename.replace('.png', '.json').replace('.jpg', '.json') # 이미지 확장자에 따라 변경\n",
    "                json_path = os.path.join(json_dir, json_filename)\n",
    "\n",
    "                # 이미지 로드 및 전처리\n",
    "                image = load_and_preprocess_image(image_path, target_size=input_shape[:2])\n",
    "                batch_images.append(image)\n",
    "\n",
    "                # JSON 레이블 로드 및 전처리\n",
    "                label_value = load_and_preprocess_json_label(json_path)\n",
    "                # 레이블을 원-핫 인코딩 또는 적절한 형태로 변환하는 로직 추가 필요\n",
    "                # 이 부분은 num_classes와 레이블의 종류에 따라 달라집니다.\n",
    "                # 예시: 정수 레이블을 원-핫 인코딩\n",
    "                one_hot_label = tf.keras.utils.to_categorical(label_value, num_classes=num_classes)\n",
    "                batch_labels.append(one_hot_label)\n",
    "\n",
    "            yield np.array(batch_images), np.array(batch_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스 생성 및 컴파일\n",
    "model = model(input_shape=input_shape, num_classes=num_classes)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "checkpoint_manager = CheckpointManager(\n",
    "    max_recent=5,  # 최근 5개의 체크포인트 유지\n",
    "    extra_interval=10 # 10 에포크마다 추가 체크포인트 저장\n",
    ")\n",
    "\n",
    "# 최신 체크포인트 로드 시도\n",
    "start_epoch = 0\n",
    "# 모든 이미지 파일 이름 가져오기\n",
    "all_image_filenames = [f for f in os.listdir(image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# 가장 최근에 저장된 에포크 찾기\n",
    "if checkpoint_manager.recent_epochs:\n",
    "    latest_epoch = max(checkpoint_manager.recent_epochs)\n",
    "    if checkpoint_manager.load(model, latest_epoch):\n",
    "        start_epoch = latest_epoch + 1\n",
    "        print(f\"restart train {start_epoch} 에포크부터 재개합니다.\")\n",
    "else:\n",
    "    print(\"저장된 체크포인트가 없습니다. 모델을 처음부터 훈련합니다.\")\n",
    "\n",
    "# 훈련 파라미터 설정\n",
    "batch_size = 32\n",
    "target_accuracy = 0.98  # 목표 정답률\n",
    "\n",
    "# 데이터 제너레이터 생성\n",
    "train_generator = data_generator(all_image_filenames, batch_size, input_shape, num_classes)\n",
    "\n",
    "# 훈련 루프\n",
    "epoch = start_epoch\n",
    "while True:\n",
    "    print(f\"\\n에포크 {epoch} 시작...\")\n",
    "\n",
    "    # 한 에포크 동안 훈련\n",
    "    steps_per_epoch = len(all_image_filenames) // batch_size\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=1,  # 한 번에 한 에포크씩 훈련\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 현재 에포크의 정답률 확인\n",
    "    current_accuracy = history.history['accuracy'][0]\n",
    "    print(f\"에포크 {epoch} 정답률: {current_accuracy:.4f}\")\n",
    "\n",
    "    # 체크포인트 저장\n",
    "    checkpoint_manager.save(model, epoch)\n",
    "\n",
    "    # 목표 정답률 달성 여부 확인\n",
    "    if current_accuracy >= target_accuracy:\n",
    "        print(f\"목표 정답률 {target_accuracy:.4f}에 도달했습니다. 훈련을 중단합니다.\")\n",
    "        break\n",
    "\n",
    "    epoch += 1\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN0UZbM/LP9PJyk3I/d6VMI",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
