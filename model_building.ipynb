{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0UZbM/LP9PJyk3I/d6VMI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stayup24h/Hangul-to-Unicode-Obfuscation-Project/blob/main/model_building.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3de343a7"
      },
      "source": [
        "import requests\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "\n",
        "base_url = \"https://api.aihub.or.kr/aihubdata/data/view.do\"\n",
        "\n",
        "api_key = userdata.get('AI_HUB')\n",
        "\n",
        "# Parameters for the API request (adjust as needed based on the specific API documentation)\n",
        "params = {\n",
        "    \"currMenu\": 115,\n",
        "    \"topMenu\": 100,\n",
        "    \"aihubDataSe\": \"data\",\n",
        "    \"dataSetSn\": 81,\n",
        "    # Add other parameters required by the API\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {api_key}\" # Or however the API requires authentication\n",
        "}\n",
        "\n",
        "try:\n",
        "    response = requests.get(base_url, params=params, headers=headers)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
        "\n",
        "    data = response.json() # Assuming the API returns JSON data\n",
        "\n",
        "    # Process the data as needed\n",
        "    print(data)\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error calling AIHUB API: {e}\")\n",
        "    if 'response' in locals():\n",
        "        print(f\"Response status code: {response.status_code}\")\n",
        "        print(f\"Response body: {response.text}\")\n",
        "    else:\n",
        "        print(\"No response received.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHqopzICGLpl"
      },
      "outputs": [],
      "source": [
        "# initial\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Reshape, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f90a1c79"
      },
      "source": [
        "def model(input_shape, num_classes):\n",
        "    model = Sequential()\n",
        "\n",
        "    # CNN layers\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Reshape for RNN layers\n",
        "    new_height = input_shape[0] // 8\n",
        "    new_width = input_shape[1] // 8\n",
        "    model.add(Reshape(target_shape=(new_width, new_height * 128)))\n",
        "\n",
        "    # RNN layers (Bidirectional LSTM)\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "    model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ZbV34u_L4QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa0fa569"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Define the path where you want to save the models\n",
        "checkpoint_path = \"training_checkpoints/epoch_{epoch:04d}/model.ckpt\"\n",
        "\n",
        "# Create a ModelCheckpoint callback\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,  # Set to False to save the entire model\n",
        "    save_freq='epoch',       # Save every epoch\n",
        "    verbose=1                # Print messages when saving\n",
        ")\n",
        "\n",
        "print(f\"Model checkpoints will be saved to: {checkpoint_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab059417"
      },
      "source": [
        "**Important:**\n",
        "\n",
        "*   Replace `\"YOUR_API_KEY\"` with your actual API key obtained from AIHUB.\n",
        "*   The `base_url` and `params` in the code are based on the URL you provided, but you should consult the specific API documentation for the exact endpoint and required parameters for fetching Korean font image data.\n",
        "*   The authentication method (`headers`) might vary. Check the API documentation for how to include your API key in the request.\n",
        "*   The code assumes the API returns JSON data. If the data is in a different format, you'll need to adjust the parsing accordingly.\n",
        "*   Error handling is included, but you might want to add more specific error handling based on the API's response structure."
      ]
    }
  ]
}