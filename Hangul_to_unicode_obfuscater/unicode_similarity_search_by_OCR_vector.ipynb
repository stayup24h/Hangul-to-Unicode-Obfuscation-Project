{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stayup24h/Hangul-to-Unicode-Obfuscation-Project/blob/main/unicode_similarity_search_by_OCR_vector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeIYCo_PWuXB",
        "outputId": "40752a96-488b-4165-b1eb-01c3685d3b06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras import Model\n",
        "from sklearn.model_selection import KFold\n",
        "from copy import deepcopy # 각 폴드마다 새로운 모델을 시작하기 위함\n",
        "from google.colab import drive\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "S1plIz5QWj1a"
      },
      "outputs": [],
      "source": [
        "# autoencoder 정의\n",
        "\n",
        "def compiled_autoencoder(input_dim=68, latent_dim=16):\n",
        "    \"\"\"Autoencoder 모델을 정의하고 컴파일하여 반환합니다.\"\"\"\n",
        "\n",
        "    # 1. Encoder 정의\n",
        "    input_layer = tf.keras.layers.Input(shape=(input_dim,), name='input_vector')\n",
        "    x = tf.keras.layers.Dense(32, activation='relu')(input_layer)\n",
        "    latent_vector = tf.keras.layers.Dense(latent_dim, activation='relu', name='latent_vector')(x)\n",
        "    encoder = Model(input_layer, latent_vector, name='encoder')\n",
        "\n",
        "    # 2. Decoder 정의\n",
        "    latent_input = tf.keras.layers.Input(shape=(latent_dim,), name='latent_input')\n",
        "    y = tf.keras.layers.Dense(32, activation='relu')(latent_input)\n",
        "    reconstruction = tf.keras.layers.Dense(input_dim, activation='sigmoid', name='reconstruction')(y)\n",
        "    decoder = Model(latent_input, reconstruction, name='decoder')\n",
        "\n",
        "    # 3. Autoencoder 정의\n",
        "    autoencoder_output = decoder(encoder(input_layer))\n",
        "    autoencoder = Model(input_layer, autoencoder_output, name='autoencoder')\n",
        "\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=1e-5, momentum=0.9)\n",
        "\n",
        "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
        "                                                  restore_best_weights=True,\n",
        "                                                  monitor='loss')\n",
        "\n",
        "    lr_scheduler_cb = keras.callbacks.ReduceLROnPlateau(monitor='loss',\n",
        "                                                    factor=0.1,\n",
        "                                                    patience=3)\n",
        "\n",
        "    autoencoder.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "    return autoencoder, encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lLGfyvR_c3J1",
        "outputId": "b48cd015-1b05-45b9-aed7-8b0c140e7aa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_0.npy' loaded. Shape: (14805, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_0.npy' loaded. Shape: (16384, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_1.npy' loaded. Shape: (16374, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_1.npy' loaded. Shape: (16384, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_2.npy' loaded. Shape: (11023, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_2.npy' loaded. Shape: (16384, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_3.npy' loaded. Shape: (1504, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_3.npy' loaded. Shape: (16384, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_4.npy' loaded. Shape: (7334, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_4.npy' loaded. Shape: (16384, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_5.npy' loaded. Shape: (5785, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_5.npy' loaded. Shape: (16384, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_6.npy' loaded. Shape: (4081, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_6.npy' loaded. Shape: (16384, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_7.npy' loaded. Shape: (5024, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_7.npy' loaded. Shape: (16384, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_8.npy' loaded. Shape: (907, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_8.npy' loaded. Shape: (16384, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_9.npy' loaded. Shape: (788, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_9.npy' loaded. Shape: (16384, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_10.npy' loaded. Shape: (505, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_10.npy' loaded. Shape: (16384, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_11.npy' loaded. Shape: (161, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_11.npy' loaded. Shape: (16384, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_12.npy' loaded. Shape: (4, 68)\n",
            "'/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_12.npy' loaded. Shape: (631, 68)\n",
            "All NPY files concatenated successfully. Total Shape: (265534, 68)\n",
            "\n",
            "Starting Training...\n",
            "Epoch 1/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 46.8275\n",
            "Epoch 2/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 42.6195\n",
            "Epoch 3/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 42.5837\n",
            "Epoch 4/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 42.4253\n",
            "Epoch 5/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 42.4226\n",
            "Epoch 6/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 42.6213\n",
            "Epoch 7/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 42.4782\n",
            "Epoch 8/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 42.5187\n",
            "Epoch 9/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 42.4931\n",
            "Epoch 10/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 42.4575\n",
            "Epoch 11/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 42.4535\n",
            "Epoch 12/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 42.4815\n",
            "Epoch 13/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 42.5190\n",
            "Epoch 14/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 42.5326\n",
            "Epoch 15/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 42.5265\n",
            "Epoch 16/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 42.5828\n",
            "Epoch 17/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 42.5638\n",
            "Epoch 18/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 42.5576\n",
            "Epoch 19/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 42.5365\n",
            "Epoch 20/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 42.5010\n",
            "Epoch 21/200\n",
            "\u001b[1m4149/4149\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 42.5307\n",
            "Epoch 22/200\n",
            "\u001b[1m 629/4149\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 42.7005"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2370727925.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m history = autoencoder.fit(\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mX_features\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Autoencoder는 입력과 출력이 동일\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "NPY_FILE_PATHS = []\n",
        "\n",
        "for i in range(13):\n",
        "    NPY_FILE_PATHS.append(f\"/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_{i}.npy\")\n",
        "    NPY_FILE_PATHS.append(f\"/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_{i}.npy\")\n",
        "\n",
        "loaded_arrays = []\n",
        "for file_path in NPY_FILE_PATHS:\n",
        "    if os.path.exists(file_path):\n",
        "        loaded_arrays.append(np.load(file_path))\n",
        "        print(f\"'{file_path}' loaded. Shape: {loaded_arrays[-1].shape}\")\n",
        "    else:\n",
        "        print(f\"Warning: File not found at '{file_path}'. Skipping.\")\n",
        "\n",
        "if not loaded_arrays:\n",
        "    raise FileNotFoundError(\"No NPY files were loaded from the specified paths.\")\n",
        "\n",
        "X_features = np.concatenate(loaded_arrays, axis=0)\n",
        "print(f\"All NPY files concatenated successfully. Total Shape: {X_features.shape}\")\n",
        "\n",
        "\n",
        "N = X_features.shape[0]\n",
        "INPUT_DIM = X_features.shape[1]\n",
        "\n",
        "if INPUT_DIM != 68:\n",
        "    print(f\"경고: 로드된 데이터의 차원({INPUT_DIM})이 예상된 68차원과 다릅니다. 확인해주세요.\")\n",
        "\n",
        "LATENT_DIM = 16\n",
        "EPOCHS = 200\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "autoencoder, encoder_model = compiled_autoencoder(INPUT_DIM, LATENT_DIM)\n",
        "\n",
        "print(\"\\nStarting Training...\")\n",
        "\n",
        "\n",
        "history = autoencoder.fit(\n",
        "    x= X_features,\n",
        "    y= X_features,  # Autoencoder는 입력과 출력이 동일\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.title('Autoencoder Training History')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "save_path = 'best_simple_encoder_for_faiss.h5'\n",
        "encoder_model.save(save_path)\n",
        "print(f\"\\nEncoder Model saved successfully at '{save_path}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G02TOIlKeV9Z"
      },
      "outputs": [],
      "source": [
        "# 68차원 벡터들을 16차원 벡터들로 변환\n",
        "\n",
        "best_encoder = load_model('best_kf_encoder_for_faiss.h5')\n",
        "\n",
        "# TODO : 유니코드를 OCR한 68차원 numpy 배열 불러오기\n",
        "\n",
        "# X_features_all = np.load('all_unicode_features.npy')\n",
        "N = 200000 #numpy 배열 크기\n",
        "INPUT_DIM = 68\n",
        "X_features_all = np.random.rand(N, INPUT_DIM).astype('float32') # 예시 데이터\n",
        "\n",
        "X_16dim_vectors = best_encoder.predict(X_features_all)\n",
        "\n",
        "X_16dim_vectors = X_16dim_vectors.astype('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWRgt5XDe0nj"
      },
      "outputs": [],
      "source": [
        "# 변환한 벡터들 저장\n",
        "\n",
        "VECTOR_OUTPUT_FILENAME = \"faiss_16dim_vectors.npy\"\n",
        "\n",
        "np.save(VECTOR_OUTPUT_FILENAME, X_16dim_vectors)\n",
        "\n",
        "print(f\"16차원 잠재 벡터가 {VECTOR_OUTPUT_FILENAME}에 저장되었습니다. (Shape: {X_16dim_vectors.shape})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIbA6EVsfGgD"
      },
      "outputs": [],
      "source": [
        "# 유니코드 코드 포인트 배열 생성 (N개의 요소)\n",
        "# 이 배열은 X_features_all을 생성했을 때의 순서와 정확히 일치해야 합니다.\n",
        "# 예시: 한글 외 유니코드 코드 포인트만 순서대로 나열\n",
        "# [0x0000, 0x0001, ..., 0x00A0, ..., 0x10FFFF] (제외 범위 제외)\n",
        "unicode_codepoints = np.array([\n",
        "    # 실제 데이터셋을 만들 때 사용된 코드 포인트를 순서대로 여기에 배치해야 함.\n",
        "    i for i in range(N) # 예시에서는 N개의 임의 인덱스라고 가정\n",
        "])\n",
        "\n",
        "MAPPING_OUTPUT_FILENAME = \"faiss_unicode_map.npy\"\n",
        "np.save(MAPPING_OUTPUT_FILENAME, unicode_codepoints)\n",
        "\n",
        "print(f\"유니코드 코드 포인트 매핑이 {MAPPING_OUTPUT_FILENAME}에 저장되었습니다. (Shape: {unicode_codepoints.shape})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qq8gl9dnpplX",
        "outputId": "bc1bc6c7-6d43-4420-a5e1-4f6e0c791fbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install faiss-cpu numpy\n",
        "%pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up1dikElpplX",
        "outputId": "64c4e4bb-6a01-4e93-e223-a088c748b902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Unicode 데이터 로딩 시작 ---\n",
            "Loaded: 'unicode_results_0.npy' | Shape: (14805, 68)\n",
            "Loaded: 'combined_unicode_results_0.npy' | Shape: (16384, 68)\n",
            "Loaded: 'unicode_results_1.npy' | Shape: (16374, 68)\n",
            "Loaded: 'combined_unicode_results_1.npy' | Shape: (16384, 68)\n",
            "Loaded: 'unicode_results_2.npy' | Shape: (11023, 68)\n",
            "Loaded: 'combined_unicode_results_2.npy' | Shape: (16384, 68)\n",
            "Loaded: 'unicode_results_3.npy' | Shape: (1504, 68)\n",
            "Loaded: 'combined_unicode_results_3.npy' | Shape: (16384, 68)\n",
            "Loaded: 'unicode_results_4.npy' | Shape: (7334, 68)\n",
            "Loaded: 'combined_unicode_results_4.npy' | Shape: (16384, 68)\n",
            "Loaded: 'unicode_results_5.npy' | Shape: (5785, 68)\n",
            "Loaded: 'combined_unicode_results_5.npy' | Shape: (16384, 68)\n",
            "Loaded: 'unicode_results_6.npy' | Shape: (4081, 68)\n",
            "Loaded: 'combined_unicode_results_6.npy' | Shape: (16384, 68)\n",
            "Loaded: 'unicode_results_7.npy' | Shape: (5024, 68)\n",
            "Loaded: 'combined_unicode_results_7.npy' | Shape: (16384, 68)\n",
            "Loaded: 'unicode_results_8.npy' | Shape: (907, 68)\n",
            "Loaded: 'combined_unicode_results_8.npy' | Shape: (16384, 68)\n",
            "Loaded: 'unicode_results_9.npy' | Shape: (788, 68)\n",
            "Loaded: 'combined_unicode_results_9.npy' | Shape: (16384, 68)\n",
            "Loaded: 'unicode_results_10.npy' | Shape: (505, 68)\n",
            "Loaded: 'combined_unicode_results_10.npy' | Shape: (16384, 68)\n",
            "Loaded: 'unicode_results_11.npy' | Shape: (161, 68)\n",
            "Loaded: 'combined_unicode_results_11.npy' | Shape: (16384, 68)\n",
            "Loaded: 'unicode_results_12.npy' | Shape: (4, 68)\n",
            "Loaded: 'combined_unicode_results_12.npy' | Shape: (631, 68)\n",
            "\n",
            "--- Label 데이터 로딩 시작 ---\n",
            "Loaded: 'unicode_labels_0.npy' | Shape: (14805,)\n",
            "Loaded: 'combined_unicode_labels_0.npy' | Shape: (16384,)\n",
            "Loaded: 'unicode_labels_1.npy' | Shape: (16374,)\n",
            "Loaded: 'combined_unicode_labels_1.npy' | Shape: (16384,)\n",
            "Loaded: 'unicode_labels_2.npy' | Shape: (11023,)\n",
            "Loaded: 'combined_unicode_labels_2.npy' | Shape: (16384,)\n",
            "Loaded: 'unicode_labels_3.npy' | Shape: (1504,)\n",
            "Loaded: 'combined_unicode_labels_3.npy' | Shape: (16384,)\n",
            "Loaded: 'unicode_labels_4.npy' | Shape: (7334,)\n",
            "Loaded: 'combined_unicode_labels_4.npy' | Shape: (16384,)\n",
            "Loaded: 'unicode_labels_5.npy' | Shape: (5785,)\n",
            "Loaded: 'combined_unicode_labels_5.npy' | Shape: (16384,)\n",
            "Loaded: 'unicode_labels_6.npy' | Shape: (4081,)\n",
            "Loaded: 'combined_unicode_labels_6.npy' | Shape: (16384,)\n",
            "Loaded: 'unicode_labels_7.npy' | Shape: (5024,)\n",
            "Loaded: 'combined_unicode_labels_7.npy' | Shape: (16384,)\n",
            "Loaded: 'unicode_labels_8.npy' | Shape: (907,)\n",
            "Loaded: 'combined_unicode_labels_8.npy' | Shape: (16384,)\n",
            "Loaded: 'unicode_labels_9.npy' | Shape: (788,)\n",
            "Loaded: 'combined_unicode_labels_9.npy' | Shape: (16384,)\n",
            "Loaded: 'unicode_labels_10.npy' | Shape: (505,)\n",
            "Loaded: 'combined_unicode_labels_10.npy' | Shape: (16384,)\n",
            "Loaded: 'unicode_labels_11.npy' | Shape: (161,)\n",
            "Loaded: 'combined_unicode_labels_11.npy' | Shape: (16384,)\n",
            "Loaded: 'unicode_labels_12.npy' | Shape: (4,)\n",
            "Loaded: 'combined_unicode_labels_12.npy' | Shape: (631,)\n",
            "\n",
            "--- 데이터 병합 시작 ---\n",
            "✅ 최종 Unicode 배열(X) 합치기 완료!\n",
            "   최종 형태(Shape): (265534, 68)\n",
            "✅ 최종 Label 배열(Y) 합치기 완료!\n",
            "   최종 형태(Shape): (265534,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "import os\n",
        "\n",
        "UnicodeNPY_FILE_PATHS = []\n",
        "LableNPY_FILE_PATHS = []\n",
        "\n",
        "# 1. 파일 경로 생성\n",
        "for i in range(13):\n",
        "    UnicodeNPY_FILE_PATHS.append(f\"/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_results_{i}.npy\")\n",
        "    LableNPY_FILE_PATHS.append(f\"/content/drive/MyDrive/기계학습기초/datasets/unicode_images/unicode_labels_{i}.npy\")\n",
        "    UnicodeNPY_FILE_PATHS.append(f\"/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_results_{i}.npy\")\n",
        "    LableNPY_FILE_PATHS.append(f\"/content/drive/MyDrive/기계학습기초/datasets/unicode_images/combined_unicode_labels_{i}.npy\")\n",
        "\n",
        "loaded_unicode_arrays = []\n",
        "loaded_lable_arrays = []\n",
        "\n",
        "# 2. Unicode 데이터 로드\n",
        "print(\"--- Unicode 데이터 로딩 시작 ---\")\n",
        "for file_path in UnicodeNPY_FILE_PATHS:\n",
        "    if os.path.exists(file_path):\n",
        "        data = np.load(file_path)\n",
        "        loaded_unicode_arrays.append(data)\n",
        "        print(f\"Loaded: '{os.path.basename(file_path)}' | Shape: {data.shape}\")\n",
        "    else:\n",
        "        print(f\"Warning: File not found at '{file_path}'. Skipping.\")\n",
        "\n",
        "# 3. Label 데이터 로드\n",
        "print(\"\\n--- Label 데이터 로딩 시작 ---\")\n",
        "for file_path in LableNPY_FILE_PATHS:\n",
        "    if os.path.exists(file_path):\n",
        "        # allow_pickle=True 유지\n",
        "        data = np.load(file_path, allow_pickle=True)\n",
        "        loaded_lable_arrays.append(data)\n",
        "        print(f\"Loaded: '{os.path.basename(file_path)}' | Shape: {data.shape}\")\n",
        "    else:\n",
        "        print(f\"Warning: File not found at '{file_path}'. Skipping.\")\n",
        "\n",
        "# ========================================================\n",
        "# 4. 배열 합치기 (이 부분이 추가되었습니다)\n",
        "# ========================================================\n",
        "print(\"\\n--- 데이터 병합 시작 ---\")\n",
        "\n",
        "# Unicode 데이터 합치기\n",
        "if loaded_unicode_arrays:\n",
        "    final_unicode_X = np.concatenate(loaded_unicode_arrays, axis=0)\n",
        "    print(f\"✅ 최종 Unicode 배열(X) 합치기 완료!\")\n",
        "    print(f\"   최종 형태(Shape): {final_unicode_X.shape}\")\n",
        "else:\n",
        "    print(\"❌ 병합할 Unicode 데이터가 없습니다.\")\n",
        "\n",
        "# Label 데이터 합치기\n",
        "if loaded_lable_arrays:\n",
        "    final_label_Y = np.concatenate(loaded_lable_arrays, axis=0)\n",
        "    print(f\"✅ 최종 Label 배열(Y) 합치기 완료!\")\n",
        "    print(f\"   최종 형태(Shape): {final_label_Y.shape}\")\n",
        "else:\n",
        "    print(\"❌ 병합할 Label 데이터가 없습니다.\")\n",
        "\n",
        "\n",
        "FAISS_INDEX_FILENAME = \"unicode_faiss_index.faiss\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zco9rkzIpplX",
        "outputId": "1e31d3c7-984f-4877-9aa6-f8a2a1cea656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FAISS Index Training Start...\n",
            "Training Complete. Index is trained: True\n",
            "Total vectors added: 265534\n",
            "FAISS Index saved as unicode_faiss_index.faiss\n"
          ]
        }
      ],
      "source": [
        "# --- FAISS 인덱스 설정 ---\n",
        "NLIST = 500  # 클러스터(Partition) 개수. (데이터 개수의 sqrt 근처 값 권장)\n",
        "\n",
        "D = final_unicode_X\n",
        "\n",
        "# 1. Quantizer 정의: 벡터를 클러스터링할 때 사용할 기준 (일반적으로 L2 거리를 사용하는 Flat 인덱스 사용)\n",
        "# 'D' 대신 벡터의 차원 (D.shape[1])을 전달해야 합니다.\n",
        "quantizer = faiss.IndexFlatL2(D.shape[1])\n",
        "\n",
        "# 2. IVF 인덱스 생성: D차원, NLIST개의 클러스터, L2 거리 사용\n",
        "# 'D' 대신 벡터의 차원 (D.shape[1])을 전달해야 합니다.\n",
        "index = faiss.IndexIVFFlat(quantizer, D.shape[1], NLIST, faiss.METRIC_L2)\n",
        "\n",
        "# 3. 인덱스 훈련 (Training)\n",
        "# IVF 인덱스는 add 전에 클러스터 중심점을 계산하는 훈련이 필요합니다.\n",
        "print(\"FAISS Index Training Start...\")\n",
        "index.train(final_unicode_X)\n",
        "print(\"Training Complete. Index is trained:\", index.is_trained)\n",
        "\n",
        "# 4. 벡터 추가 (Adding)\n",
        "# 16차원 잠재 벡터를 인덱스에 추가합니다.\n",
        "index.add(final_unicode_X)\n",
        "print(f\"Total vectors added: {index.ntotal}\")\n",
        "\n",
        "# 5. 검색 속도 vs. 정확도 설정 (nprobe)\n",
        "# 검색 시 확인할 클러스터의 개수. 높을수록 정확하나 느립니다.\n",
        "# 20만 개에서는 10~30 사이가 적절하며, 20을 추천합니다.\n",
        "index.nprobe = 20\n",
        "\n",
        "# 6. 인덱스 저장\n",
        "faiss.write_index(index, FAISS_INDEX_FILENAME)\n",
        "print(f\"FAISS Index saved as {FAISS_INDEX_FILENAME}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#한글 이미지 생성기 로드\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from fontTools.ttLib import TTFont\n",
        "from tqdm import tqdm\n",
        "\n",
        "from search_fonts import NOTO_FONTS_NAME\n",
        "\n",
        "\n",
        "# --- 설정 ---\n",
        "IMAGE_HEIGHT = 128\n",
        "IMAGE_WIDTH = 128\n",
        "FONT_SIZE = 96  # 이미지 크기에 맞게 조절 필요\n",
        "OUTPUT_FILENAME_BASE = \"unicode_tensors\"  # unicode_tensors_{k}.npy\n",
        "OUTPUT_LABEL_BASE = \"unicode_labels\"  # unicode_labels_{k}.npy\n",
        "UNRENDERED_LOG_FILENAME = (\n",
        "    \"unrendered_characters.txt\"  # 렌더 안 되는 빈 유니코드 목록 저장\n",
        ")\n",
        "\n",
        "def render_char_to_tensor(char, font_path = \"./NotoSansKR-Medium.ttf\"):\n",
        "    \"\"\"문자를 이미지로 렌더링하고 Numpy 텐서로 변환합니다.\"\"\"\n",
        "    try:\n",
        "        font = ImageFont.truetype(font_path, FONT_SIZE)\n",
        "    except IOError:\n",
        "        # Pillow가 폰트 파일을 열지 못하는 경우\n",
        "        return None\n",
        "\n",
        "    image = Image.new(\"L\", (IMAGE_WIDTH, IMAGE_HEIGHT), \"white\")\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    # 문자를 이미지 중앙에 정렬하기 위해 바운딩 박스 계산\n",
        "    try:\n",
        "        bbox = draw.textbbox((0, 0), char, font=font)\n",
        "        text_width = bbox[2] - bbox[0]\n",
        "        text_height = bbox[3] - bbox[1]\n",
        "        position = (\n",
        "            (IMAGE_WIDTH - text_width) / 2 - bbox[0],\n",
        "            (IMAGE_HEIGHT - text_height) / 2 - bbox[1],\n",
        "        )\n",
        "    except Exception:\n",
        "        # 일부 특수 문자는 bbox 계산에 실패할 수 있음\n",
        "        position = (5, 5)\n",
        "\n",
        "    draw.text(position, char, font=font, fill=\"black\")\n",
        "\n",
        "    # 이미지를 Numpy 배열로 변환하고 0~1 사이 값으로 정규화\n",
        "    tensor = np.array(image, dtype=np.float32) / 255.0\n",
        "\n",
        "    # reshape()의 첫 번째 차원은 제거합니다. 배열에 직접 할당할 것이기 때문입니다.\n",
        "    return tensor.reshape((IMAGE_WIDTH, IMAGE_HEIGHT, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SQ7NU5cGu-d"
      },
      "outputs": [],
      "source": [
        "#OCR 모델 로드\n",
        "MODEL_PATH = \"./final.keras\"\n",
        "\n",
        "L_SLICE = slice(0, 19)\n",
        "V_SLICE = slice(19, 40)\n",
        "T_SLICE = slice(40, 68)\n",
        "\n",
        "def hangul_loss(y_true, logits):\n",
        "    cho  = tf.nn.softmax_cross_entropy_with_logits(labels=y_true[:, L_SLICE], logits=logits[:, L_SLICE])\n",
        "    jung = tf.nn.softmax_cross_entropy_with_logits(labels=y_true[:, V_SLICE], logits=logits[:, V_SLICE])\n",
        "    jong = tf.nn.softmax_cross_entropy_with_logits(labels=y_true[:, T_SLICE], logits=logits[:, T_SLICE])\n",
        "    return cho + jung + jong\n",
        "\n",
        "def acc_first(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_true[:, L_SLICE], -1),\n",
        "                                           tf.argmax(y_pred[:, L_SLICE], -1)), tf.float32))\n",
        "def acc_middle(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_true[:, V_SLICE], -1),\n",
        "                                           tf.argmax(y_pred[:, V_SLICE], -1)), tf.float32))\n",
        "def acc_last(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_true[:, T_SLICE], -1),\n",
        "                                           tf.argmax(y_pred[:, T_SLICE], -1)), tf.float32))\n",
        "def acc_joint(y_true, y_pred):\n",
        "    l_ok = tf.equal(tf.argmax(y_true[:, L_SLICE], -1), tf.argmax(y_pred[:, L_SLICE], -1))\n",
        "    v_ok = tf.equal(tf.argmax(y_true[:, V_SLICE], -1), tf.argmax(y_pred[:, V_SLICE], -1))\n",
        "    t_ok = tf.equal(tf.argmax(y_true[:, T_SLICE], -1), tf.argmax(y_pred[:, T_SLICE], -1))\n",
        "    return tf.reduce_mean(tf.cast(l_ok & v_ok & t_ok, tf.float32))\n",
        "\n",
        "# --- 모델 로드 ---\n",
        "model = tf.keras.models.load_model(\n",
        "    MODEL_PATH,\n",
        "    custom_objects={\n",
        "        \"hangul_loss\": hangul_loss,\n",
        "        \"acc_first\": acc_first,\n",
        "        \"acc_middle\": acc_middle,\n",
        "        \"acc_last\": acc_last,\n",
        "        \"acc_joint\": acc_joint,\n",
        "    }\n",
        ")\n",
        "\n",
        "def ocr(character):\n",
        "    X = render_char_to_tensor(character)                               # shape: (N, 128,128,1)\n",
        "\n",
        "    if X.ndim == 3:\n",
        "        X = np.expand_dims(X, -1)\n",
        "    X = X.astype(np.float32)\n",
        "    if np.max(X) > 1.5:\n",
        "        X /= 255.0                                  # 정규화\n",
        "\n",
        "    print(f\"▶ Predicting {f_in} -> {out_path} (shape={X.shape})\")\n",
        "\n",
        "    # 모델 예측\n",
        "    preds = model.predict(X, batch_size=256, verbose=1)  # (N,68)\n",
        "\n",
        "    return pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "Dqcq1DKfpplY",
        "outputId": "1d0edfd4-ef6e-401b-866b-c15349f93efb"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'query_encoder' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-173816480.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# --- 사용 예시 ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0minput_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"한\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0msimilar_chars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_similar_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"--- '{input_char}'와 시각적으로 유사한 상위 10개 유니코드 문자 ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-173816480.py\u001b[0m in \u001b[0;36mfind_similar_unicode\u001b[0;34m(korean_char, k)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# 쿼리 벡터를 16차원 잠재 벡터로 변환\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mq_16dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_q_68dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mq_16dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_16dim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# FAISS 요구 타입\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'query_encoder' is not defined"
          ]
        }
      ],
      "source": [
        "# FAISS 인덱스 로드\n",
        "index = faiss.read_index(FAISS_INDEX_FILENAME)\n",
        "\n",
        "def find_similar_unicode(korean_char, k=5):\n",
        "    \"\"\"\n",
        "    한글 문자를 입력받아 시각적으로 가장 유사한 K개의 유니코드 문자를 반환합니다.\n",
        "    \"\"\"\n",
        "\n",
        "    char_vector = ocr(korean_char)\n",
        "\n",
        "\n",
        "\n",
        "    D, I = index.search(char_vector, k)\n",
        "\n",
        "    # --- 3. 결과 해석 및 반환 ---\n",
        "    results = []\n",
        "\n",
        "    # 가장 가까운 이웃의 인덱스와 거리를 순회합니다.\n",
        "    for rank, (idx, distance) in enumerate(zip(I[0], D[0])):\n",
        "        if idx >= 0: # 유효한 인덱스일 경우\n",
        "            code_point = U_map[idx]\n",
        "            unicode_char = chr(code_point)\n",
        "\n",
        "            results.append({\n",
        "                \"Rank\": rank + 1,\n",
        "                \"Character\": unicode_char,\n",
        "                \"CodePoint\": f\"U+{code_point:04X}\",\n",
        "                \"Similarity_Distance\": float(distance) # 거리가 낮을수록 유사\n",
        "            })\n",
        "\n",
        "    return results\n",
        "\n",
        "# --- 사용 예시 ---\n",
        "input_char = \"한\"\n",
        "similar_chars = find_similar_unicode(input_char, k=10)\n",
        "\n",
        "print(f\"--- '{input_char}'와 시각적으로 유사한 상위 10개 유니코드 문자 ---\")\n",
        "for result in similar_chars:\n",
        "    print(\n",
        "        f\"[{result['Rank']}] {result['Character']} \"\n",
        "        f\"({result['CodePoint']}) - Distance: {result['Similarity_Distance']:.4f}\"\n",
        "    )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
