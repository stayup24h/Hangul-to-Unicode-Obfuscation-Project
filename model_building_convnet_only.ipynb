{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stayup24h/Hangul-to-Unicode-Obfuscation-Project/blob/main/model_building_convnet_only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 자기 계정의 드라이브를 코랩 폴더에 마운트함\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_u1nlFAu_7nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNSFK77lZAOa",
        "outputId": "0ad745d5-2edf-4542-9b76-261070cb70c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "id": "1DsgQVNbGJBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHqopzICGLpl"
      },
      "outputs": [],
      "source": [
        "# initial\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Reshape, LSTM, Dense, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 주무르기\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# numpy tensor 한 개\n",
        "my_tensor = np.load(\"/content/drive/MyDrive/datasets/tensor_printed_0.npy\")\n",
        "\n",
        "# tensor 모양 출력\n",
        "print(\"Shape of my_tensor:\", my_tensor.shape)\n",
        "\n",
        "# 채널 차원이 없으니 하나 추가 (50000, 150, 150) -> (50000, 150, 150, 1)\n",
        "my_tensor = np.expand_dims(my_tensor, axis=-1)\n",
        "\n",
        "# 64 * 64으로 변경 (50000, 150, 150, 1) -> (50000, 64, 64, 1)\n",
        "my_tensor = np.array([tf.image.resize(img, (64, 64)) for img in my_tensor])\n",
        "\n",
        "# float 노멀라이징\n",
        "my_tensor = my_tensor.astype(np.float32) / 255.0"
      ],
      "metadata": {
        "id": "cp9q7kTnAW-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor.shape"
      ],
      "metadata": {
        "id": "yoWwUJC9ObCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28ebbe3c"
      },
      "source": [
        "# Load the labels\n",
        "labels = np.load(\"/content/drive/MyDrive/datasets/tensor_printed_0_labels.npy\")\n",
        "\n",
        "# Print the shape of the labels\n",
        "print(\"Shape of labels:\", labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f90a1c79"
      },
      "outputs": [],
      "source": [
        "# 모델 설계\n",
        "def model(input_shape):\n",
        "    input_layer = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape)(input_layer)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = layers.Flatten()(x)\n",
        "\n",
        "    cho = layers.Dense(19, activation='softmax', name=\"cho\")(x)\n",
        "    jung = layers.Dense(21, activation='softmax', name=\"jung\")(x)\n",
        "    jong = layers.Dense(28, activation='softmax', name=\"jong\")(x)\n",
        "    model = Model(inputs=input_layer, outputs=[cho, jung, jong])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa0fa569"
      },
      "outputs": [],
      "source": [
        "# 모델 체크포인트 관리 클래스\n",
        "\n",
        "checkpoint_path = \"training_checkpoints/epoch_{epoch:04d}/model.weights.h5\"\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    save_freq='epoch'\n",
        ")\n",
        "\n",
        "class CheckpointManager:\n",
        "    def __init__(self, checkpoint_path_template, max_recent=3, extra_interval=50):\n",
        "        self.checkpoint_path_template = checkpoint_path_template\n",
        "        self.max_recent = max_recent\n",
        "        self.extra_interval = extra_interval\n",
        "        self.recent_epochs = []\n",
        "\n",
        "    def load(self, model, epoch, checkpoint_path_template=checkpoint_path):\n",
        "        path = checkpoint_path_template.format(epoch=epoch)\n",
        "        if os.path.exists(path):\n",
        "            model.load_weights(path)\n",
        "            print(f\"Loaded weights from {path}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"No checkpoint found at {path}\")\n",
        "            return False\n",
        "\n",
        "    def save(self, model, epoch):\n",
        "        # Always save at extra_interval epochs\n",
        "        if epoch % self.extra_interval == 0 and epoch not in self.recent_epochs:\n",
        "            path = self.checkpoint_path_template.format(epoch=epoch)\n",
        "            model.save_weights(path)\n",
        "            print(f\"Extra checkpoint saved for epoch {epoch} at {path}\")\n",
        "\n",
        "        # Save recent checkpoints\n",
        "        self.recent_epochs.append(epoch)\n",
        "        if len(self.recent_epochs) > self.max_recent:\n",
        "            # Remove oldest checkpoint from recent\n",
        "            old_epoch = self.recent_epochs.pop(0)\n",
        "            old_path = self.checkpoint_path_template.format(epoch=old_epoch)\n",
        "            if os.path.exists(old_path):\n",
        "                os.remove(old_path)\n",
        "                print(f\"Removed old checkpoint at {old_path}\")\n",
        "\n",
        "        path = self.checkpoint_path_template.format(epoch=epoch)\n",
        "        model.save_weights(path)\n",
        "        print(f\"Checkpoint saved for epoch {epoch} at {path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "the_model = model((64, 64, 1))\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "the_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy', 'accuracy', 'accuracy'])\n",
        "the_model.summary()"
      ],
      "metadata": {
        "id": "LSmYiTIEEz7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cho_labels = labels[:, :19]\n",
        "jung_labels = labels[:, 19:19+21]\n",
        "jong_labels = labels[:, 19+21:]\n",
        "\n",
        "the_model.fit(my_tensor, [cho_labels, jung_labels, jong_labels], epochs=10)"
      ],
      "metadata": {
        "id": "xBjatkT1GvyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37d0773b"
      },
      "source": [
        "# Make predictions on a small subset of the data\n",
        "predictions = the_model.predict(my_tensor[:10])\n",
        "\n",
        "# The predictions will be a list of arrays, one for each output (cho, jung, jong)\n",
        "cho_predictions = predictions[0]\n",
        "jung_predictions = predictions[1]\n",
        "jong_predictions = predictions[2]\n",
        "\n",
        "# Print the predictions\n",
        "print(\"Cho predictions:\\n\", cho_predictions)\n",
        "print(\"\\nJung predictions:\\n\", jung_predictions)\n",
        "print(\"\\nJong predictions:\\n\", jong_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}